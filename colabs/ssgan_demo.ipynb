{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSGAN_Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "BhN1AplL0Hpv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhN1AplL0Hpv",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMgeG2swVVi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqBuuwrIxlGs",
        "colab_type": "text"
      },
      "source": [
        "# SSGAN Demo\n",
        "\n",
        "This notebook is a demo of Generative Adversarial Networks (GANs) trained on ImageNet without labels using self-supervised techniques. Both generator and discrimantor models are available on [TF Hub](https://tfhub.dev/s?publisher=google&q=compare_gan).\n",
        "\n",
        "For more information about the models and the training procedure see our  [paper](https://arxiv.org/abs/1811.11212) [1]. \n",
        "The code for training these models is available on [GitHub](https://github.com/google/compare_gan).\n",
        "\n",
        "To get started, connect to a runtime and follow these steps:\n",
        "\n",
        "1. (Optional) Select a model in the second code cell below.\n",
        "2. Click **Runtime > Run all** to run each cell in order.\n",
        "  * Afterwards, the interactive visualizations should update automatically when you modify the settings using the sliders and dropdown menus.\n",
        "\n",
        "Note: if you run into any issues, youn can try restarting the runtime and rerunning all cells from scratch by clicking **Runtime > Restart and run all...**.\n",
        "\n",
        "[1] Ting Chen, Xiaohua Zhai, Marvin Ritter, Mario Lucic, Neil Houlsby, [Self-Supervised GANs via Auxiliary Rotation Loss](https://arxiv.org/abs/1811.11212), CVPR 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m5jsOM9kXWP",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhlMa_tHs0_W",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Imports and utility functions\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import IPython\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pandas as pd\n",
        "import six\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "def imgrid(imarray, cols=8, pad=1):\n",
        "  pad = int(pad)\n",
        "  assert pad >= 0\n",
        "  cols = int(cols)\n",
        "  assert cols >= 1\n",
        "  N, H, W, C = imarray.shape\n",
        "  rows = int(np.ceil(N / float(cols)))\n",
        "  batch_pad = rows * cols - N\n",
        "  assert batch_pad >= 0\n",
        "  post_pad = [batch_pad, pad, pad, 0]\n",
        "  pad_arg = [[0, p] for p in post_pad]\n",
        "  imarray = np.pad(imarray, pad_arg, 'constant')\n",
        "  H += pad\n",
        "  W += pad\n",
        "  grid = (imarray\n",
        "          .reshape(rows, cols, H, W, C)\n",
        "          .transpose(0, 2, 1, 3, 4)\n",
        "          .reshape(rows*H, cols*W, C))\n",
        "  return grid[:-pad, :-pad]\n",
        "\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  if six.PY3:\n",
        "    str_file = six.BytesIO()\n",
        "  else:\n",
        "    str_file = six.StringIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  png_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = display(IPython.display.Image(png_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "\n",
        "class Generator(object):\n",
        "\n",
        "  def __init__(self, module_spec):\n",
        "    self._module_spec = module_spec\n",
        "    self._sess = None\n",
        "    self._graph = tf.Graph()\n",
        "    self._load_model()\n",
        "\n",
        "  @property\n",
        "  def z_dim(self):\n",
        "    return self._z.shape[-1].value\n",
        "\n",
        "  @property\n",
        "  def conditional(self):\n",
        "    return self._labels is not None\n",
        "\n",
        "  def _load_model(self):\n",
        "    with self._graph.as_default():\n",
        "      self._generator = hub.Module(self._module_spec, name=\"gen_module\",\n",
        "                                   tags={\"gen\", \"bsNone\"})\n",
        "      input_info = self._generator.get_input_info_dict()\n",
        "      inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n",
        "                for k, v in self._generator.get_input_info_dict().items()}\n",
        "      self._samples = self._generator(inputs=inputs, as_dict=True)[\"generated\"]\n",
        "      print(\"Inputs:\", inputs)\n",
        "      print(\"Outputs:\", self._samples)\n",
        "      self._z = inputs[\"z\"]\n",
        "      self._labels = inputs.get(\"labels\", None)\n",
        "\n",
        "  def _init_session(self):\n",
        "    if self._sess is None:\n",
        "      self._sess = tf.Session(graph=self._graph)\n",
        "      self._sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  def get_noise(self, num_samples, seed=None):\n",
        "    if np.isscalar(seed):\n",
        "      np.random.seed(seed)\n",
        "      return np.random.normal(size=[num_samples, self.z_dim])\n",
        "    z = np.empty(shape=(len(seed), self.z_dim), dtype=np.float32)\n",
        "    for i, s in enumerate(seed):\n",
        "      np.random.seed(s)\n",
        "      z[i] = np.random.normal(size=[self.z_dim])\n",
        "    return z\n",
        "\n",
        "  def get_samples(self, z, labels=None):\n",
        "    with self._graph.as_default():\n",
        "      self._init_session()\n",
        "      feed_dict = {self._z: z}\n",
        "      if self.conditional:\n",
        "        assert labels is not None\n",
        "        assert labels.shape[0] == z.shape[0]\n",
        "        feed_dict[self._labels] = labels\n",
        "      samples = self._sess.run(self._samples, feed_dict=feed_dict)\n",
        "      return np.uint8(np.clip(256 * samples, 0, 255))\n",
        "\n",
        "\n",
        "class Discriminator(object):\n",
        "\n",
        "  def __init__(self, module_spec):\n",
        "    self._module_spec = module_spec\n",
        "    self._sess = None\n",
        "    self._graph = tf.Graph()\n",
        "    self._load_model()\n",
        "\n",
        "  @property\n",
        "  def conditional(self):\n",
        "    return \"labels\" in self._inputs\n",
        "\n",
        "  @property\n",
        "  def image_shape(self):\n",
        "    return self._inputs[\"images\"].shape.as_list()[1:]\n",
        "\n",
        "  def _load_model(self):\n",
        "    with self._graph.as_default():\n",
        "      self._discriminator = hub.Module(self._module_spec, name=\"disc_module\",\n",
        "                                       tags={\"disc\", \"bsNone\"})\n",
        "      input_info = self._discriminator.get_input_info_dict()\n",
        "      self._inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n",
        "                      for k, v in input_info.items()}\n",
        "      self._outputs = self._discriminator(inputs=self._inputs, as_dict=True)\n",
        "      print(\"Inputs:\", self._inputs)\n",
        "      print(\"Outputs:\", self._outputs)\n",
        "\n",
        "  def _init_session(self):\n",
        "    if self._sess is None:\n",
        "      self._sess = tf.Session(graph=self._graph)\n",
        "      self._sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  def predict(self, images, labels=None):\n",
        "    with self._graph.as_default():\n",
        "      self._init_session()\n",
        "      feed_dict = {self._inputs[\"images\"]: images}\n",
        "      if \"labels\" in self._inputs:\n",
        "        assert labels is not None\n",
        "        assert labels.shape[0] == images.shape[0]\n",
        "        feed_dict[self._inputs[\"labels\"]] = labels\n",
        "      return self._sess.run(self._outputs, feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msTFS1UPkugr",
        "colab_type": "text"
      },
      "source": [
        "## Select a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hBEi9IFdoI-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Load Model\n",
        "\n",
        "model_name = \"SSGAN 128x128 (FID 20.6, IS 24.9)\"\n",
        "models = {\n",
        "    \"SSGAN 128x128\": \"https://tfhub.dev/google/compare_gan/ssgan_128x128/1\",\n",
        "}\n",
        "\n",
        "module_spec = models[model_name.split(\" (\")[0]]\n",
        "print(\"Module spec:\", module_spec)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "print(\"Loading model...\")\n",
        "sampler = Generator(module_spec)\n",
        "print(\"Model loaded.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePQuAme_kxLj",
        "colab_type": "text"
      },
      "source": [
        "## Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGgTXtFYq_FV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Sampling { run: \"auto\" }\n",
        "\n",
        "num_rows = 3  # @param {type: \"slider\", min:1, max:16}\n",
        "num_cols = 4  # @param {type: \"slider\", min:1, max:16}\n",
        "noise_seed = 23  # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "num_samples = num_rows * num_cols\n",
        "z = sampler.get_noise(num_samples, seed=noise_seed)\n",
        "\n",
        "samples = sampler.get_samples(z)\n",
        "imshow(imgrid(samples, cols=num_cols))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCffdVZvTtxL",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Interpolation { run: \"auto\" }\n",
        "\n",
        "num_samples = 1  # @param {type: \"slider\", min: 1, max: 6, step: 1}\n",
        "num_interps = 6  # @param {type: \"slider\", min: 2, max: 10, step: 1}\n",
        "noise_seed_A = 11  # @param {type: \"slider\", min: 0, max: 100, step: 1}\n",
        "noise_seed_B = 0  # @param {type: \"slider\", min: 0, max: 100, step: 1}\n",
        "\n",
        "\n",
        "def interpolate(A, B, num_interps):\n",
        "  alphas = np.linspace(0, 1, num_interps)\n",
        "  if A.shape != B.shape:\n",
        "    raise ValueError('A and B must have the same shape to interpolate.')\n",
        "  return np.array([((1-a)*A + a*B)/np.sqrt(a**2 + (1-a)**2) for a in alphas])\n",
        "\n",
        "\n",
        "def interpolate_and_shape(A, B, num_interps):\n",
        "  interps = interpolate(A, B, num_interps)\n",
        "  return (interps.transpose(1, 0, *range(2, len(interps.shape)))\n",
        "                 .reshape(num_samples * num_interps, -1))\n",
        "\n",
        "\n",
        "z_A = sampler.get_noise(num_samples, seed=noise_seed_A)\n",
        "z_B = sampler.get_noise(num_samples, seed=noise_seed_B)\n",
        "z = interpolate_and_shape(z_A, z_B, num_interps)\n",
        "\n",
        "samples = sampler.get_samples(z)\n",
        "imshow(imgrid(samples, cols=num_interps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esW0Up95Ob6U",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ButxPSq0OzgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc = Discriminator(module_spec)\n",
        "\n",
        "batch_size = 4\n",
        "num_classes = 1000\n",
        "images = np.random.random(size=[batch_size] + disc.image_shape)\n",
        "\n",
        "disc.predict(images)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

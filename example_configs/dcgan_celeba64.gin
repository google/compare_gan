
# Recommended training platform: P100, V100, TPU v2-8 or TPU v3-8

dataset.name = "celeb_a"
options.architecture = "dcgan_arch"
options.batch_size = 64
options.gan_class = @ModularGAN
options.lamba = 1
options.training_steps = 100000
options.z_dim = 128

# Generator
G.batch_norm_fn = @batch_norm
standardize_batch.decay = 0.9
standardize_batch.epsilon = 1e-5

# Discriminator
options.disc_iters = 1
D.spectral_norm = False

# Loss and optimizer
loss.fn = @non_saturating
penalty.fn = @no_penalty
ModularGAN.g_lr = 0.0002
ModularGAN.g_optimizer_fn = @tf.train.AdamOptimizer
tf.train.AdamOptimizer.beta1 = 0.5
tf.train.AdamOptimizer.beta2 = 0.999
